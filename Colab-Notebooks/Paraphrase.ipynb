{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paraphrase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEaIFD/pN7oilIWAljQC+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce2a004205f747c1baa6d977883b7854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_858358c5ff854976953ae82885215fc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3547d1312d694841bd2de6a7040ad99d",
              "IPY_MODEL_0354bc75a1dd4a7f95b455453fc8738d"
            ]
          }
        },
        "858358c5ff854976953ae82885215fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3547d1312d694841bd2de6a7040ad99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5550f5993b2046eda7bd4a44646194b9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d769ce10acd64ba5b461b5d541b965fd"
          }
        },
        "0354bc75a1dd4a7f95b455453fc8738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85d6dcad7b9c427dbb46f2c73955d1ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:08&lt;00:00, 89.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59a6614a0a854a01b8b2c85001648871"
          }
        },
        "5550f5993b2046eda7bd4a44646194b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d769ce10acd64ba5b461b5d541b965fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85d6dcad7b9c427dbb46f2c73955d1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59a6614a0a854a01b8b2c85001648871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5154b87298ce4077bca8dde67e58de13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d3a9a01d6b64fdd9d8deafbeecf09ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b75fccffbfd247bd82c9afff18d6964d",
              "IPY_MODEL_2a9a11a07b834b6e99f2971651bb8250"
            ]
          }
        },
        "1d3a9a01d6b64fdd9d8deafbeecf09ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b75fccffbfd247bd82c9afff18d6964d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc01faeb2e334433827fb0ecdbbc2b81",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da28babc5c7446bdbab89e5d3ec6049b"
          }
        },
        "2a9a11a07b834b6e99f2971651bb8250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d6cbc0886d540ce83868319458c046e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:05&lt;00:00, 229B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1126c244e0d24e939e92e055740f04f9"
          }
        },
        "fc01faeb2e334433827fb0ecdbbc2b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da28babc5c7446bdbab89e5d3ec6049b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d6cbc0886d540ce83868319458c046e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1126c244e0d24e939e92e055740f04f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99c13a5d0ae14ebc9368e5c0997da1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8461ae940e3349bea83021aec3ac90bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_582f4b1e62de4ac18d8913fa64411682",
              "IPY_MODEL_424bc4bc00c04353827ef6532f38e376"
            ]
          }
        },
        "8461ae940e3349bea83021aec3ac90bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "582f4b1e62de4ac18d8913fa64411682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eee45c1d726741d291e9d8cf5c442df6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242136741,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242136741,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a668a78ce8bb437db40b872e9e305e82"
          }
        },
        "424bc4bc00c04353827ef6532f38e376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b20a09bd3444e449f9a97c8d04da889",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:04&lt;00:00, 57.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50fd06b167474d529a610cb25be68974"
          }
        },
        "eee45c1d726741d291e9d8cf5c442df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a668a78ce8bb437db40b872e9e305e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b20a09bd3444e449f9a97c8d04da889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50fd06b167474d529a610cb25be68974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feff9a619c3a41d7b2d70af0a9b7d88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_120f5850f5884406986ab27d52072dc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_926d241d3c9d4580ad46b3e196566008",
              "IPY_MODEL_98957ff00f894359aea0000a006c463f"
            ]
          }
        },
        "120f5850f5884406986ab27d52072dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "926d241d3c9d4580ad46b3e196566008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac91897e332e477bac4358fe62bf4c14",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb1fce035c5242ab91a80d6577972951"
          }
        },
        "98957ff00f894359aea0000a006c463f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0f6af553b464390be3aeba125d1bf30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  2.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd566ff884e748a8a809fd1acc9c6fd8"
          }
        },
        "ac91897e332e477bac4358fe62bf4c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb1fce035c5242ab91a80d6577972951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0f6af553b464390be3aeba125d1bf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd566ff884e748a8a809fd1acc9c6fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "881e88c71fc746c08c4b83b995835e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_728c5193752b4923817e6f3308c30408",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79ab9454c46046f897a1b548ede87e89",
              "IPY_MODEL_ec32bd8bd31a4f68898477d1be39c338"
            ]
          }
        },
        "728c5193752b4923817e6f3308c30408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "79ab9454c46046f897a1b548ede87e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_413a3bc19fbb45a09b16aee63315008e",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 21393,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 21393,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_992565b9af974b3fbd273a3816eb9e18"
          }
        },
        "ec32bd8bd31a4f68898477d1be39c338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fa3a0e366fa4474a758b99e1c9e3ca9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 21393/21393 [1:47:52&lt;00:00,  3.31it/s, loss=0.154, v_num=0, val_loss=2.35]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd6fab875ce24430b55d97948c70395e"
          }
        },
        "413a3bc19fbb45a09b16aee63315008e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "992565b9af974b3fbd273a3816eb9e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fa3a0e366fa4474a758b99e1c9e3ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd6fab875ce24430b55d97948c70395e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57603540902c44bb9b4f5eb540e6e7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da887a8692fb49b3af53ccf3545ad9b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ec5c313ccc04f8eb20d7de548c38d81",
              "IPY_MODEL_03171cdbff0c40e2a9598466930bbe68"
            ]
          }
        },
        "da887a8692fb49b3af53ccf3545ad9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "6ec5c313ccc04f8eb20d7de548c38d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6935f3a3e0f43688e24ad9ecb0f8744",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32bd274651f461495219423240cc89b"
          }
        },
        "03171cdbff0c40e2a9598466930bbe68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_917b468d2b1c4bbab80a49ebe7d47224",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1668/1668 [02:42&lt;00:00, 10.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2553c3e2b2b4214a75e7c0092de897d"
          }
        },
        "b6935f3a3e0f43688e24ad9ecb0f8744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32bd274651f461495219423240cc89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "917b468d2b1c4bbab80a49ebe7d47224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2553c3e2b2b4214a75e7c0092de897d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "564cade8cd174b029cd3fb0309f11ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d059ada38ccf422587bb5a2965770fb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8877bd13efc4a249a394fba17ac757e",
              "IPY_MODEL_72ec234f136941edbbedf1ab97596a37"
            ]
          }
        },
        "d059ada38ccf422587bb5a2965770fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8877bd13efc4a249a394fba17ac757e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1553dc027e51406e9ea132e25b1e4ddf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b84293a0ae72438c8c92061698397698"
          }
        },
        "72ec234f136941edbbedf1ab97596a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fcc6ea53c354b62b979ecf4d6c1245c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:16&lt;00:00, 71.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_111991ccfc4b48e3b023de8ed9f09d48"
          }
        },
        "1553dc027e51406e9ea132e25b1e4ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b84293a0ae72438c8c92061698397698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fcc6ea53c354b62b979ecf4d6c1245c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "111991ccfc4b48e3b023de8ed9f09d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb267d475796426fb446b34563a7f452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1aa0462c01ba4c31944d1ed41670ed2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db644836130d4af38dc37a876cae00d4",
              "IPY_MODEL_bc3fb47151ff48188e9dcf24b5650460"
            ]
          }
        },
        "1aa0462c01ba4c31944d1ed41670ed2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db644836130d4af38dc37a876cae00d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3abffa9077cf43ccaae7e907d2a06ba3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc9d1ad29fe24958a9bf966562fd3a8c"
          }
        },
        "bc3fb47151ff48188e9dcf24b5650460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ed59c36715845aa9f6e60614c1b1e13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:14&lt;00:00, 62.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cff1f564dfb74ebd9a63b3dac35573b8"
          }
        },
        "3abffa9077cf43ccaae7e907d2a06ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc9d1ad29fe24958a9bf966562fd3a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ed59c36715845aa9f6e60614c1b1e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cff1f564dfb74ebd9a63b3dac35573b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vamsi995/Paraphrase-Generator/blob/master/Paraphrase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f6uVYL1XLJI",
        "colab_type": "text"
      },
      "source": [
        "# **Paraphrase Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxnIq4cf2tng",
        "colab_type": "text"
      },
      "source": [
        "# **Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7A1lINgXduU",
        "colab_type": "text"
      },
      "source": [
        "## Quora Question Pairs\n",
        "\n",
        "The Quora Question Pairs2 dataset is a collection of question pairs from the community question-answering website Quora. The task is to determine whether a pair of questions are semantically equivalent.\n",
        "\n",
        "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
        "    'question1': Text(shape=(), dtype=tf.string),\n",
        "    'question2': Text(shape=(), dtype=tf.string),\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alioYiHVXhH8",
        "colab_type": "text"
      },
      "source": [
        "## MRPC\n",
        "\n",
        "The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent.\n",
        "\n",
        "\n",
        "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
        "    'sentence1': Text(shape=(), dtype=tf.string),\n",
        "    'sentence2': Text(shape=(), dtype=tf.string),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iJYaKkYnzv",
        "colab_type": "text"
      },
      "source": [
        "## MS COCO Annotations\n",
        "\n",
        "\n",
        "COCO (*Common objects in context*) is a large-scale object detection, segmentation, and captioning dataset. Roughly each example in the dataset consists of an image, its captions and its label. All the examples in the dataset are segregated into 80 classes. And each image has 5 annoted captions for each image. These 5 captions try to explain the image, and hence are paraphrased sentences. We will be breaking this set of 5 captions per each image into two example pairs and leaving out one. \n",
        "\n",
        "\n",
        "    'caption': Text(shape=(), dtype=tf.string,\n",
        "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
        "    'image/filename': Text(shape=(), dtype=tf.string),\n",
        "    'image/id': tf.int64,\n",
        "    'objects': Sequence({\n",
        "        'area': tf.int64,\n",
        "        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
        "        'id': tf.int64,\n",
        "        'is_crowd': tf.bool,\n",
        "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=80),\n",
        "    }),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2gJ5EV12trx",
        "colab_type": "text"
      },
      "source": [
        "# **What models can be used**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DBl7JPyjtKz",
        "colab_type": "text"
      },
      "source": [
        "## T5 (Encoder decoder transformer)\n",
        "\n",
        "\n",
        "  T5 (*Text-to-text Transfer Transformer*) is yet another transformer model for Google Research Group. This is a vanilla transformer i.e this model has both the encoder and decoder layers as described in the paper [ Attention is All You Need](https://arxiv.org/abs/1706.03762). T5 is a encoder-decoder model that reaches SOTA results by solving NLP problems with a text-to-text approach. This is where text is used as both an input and an output for solving all types of tasks. This was introduced in the recent paper, Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer ([paper](https://arxiv.org/abs/1910.10683)).\n",
        "\n",
        "  ![](https://1.bp.blogspot.com/-89OY3FjN0N0/XlQl4PEYGsI/AAAAAAAAFW4/knj8HFuo48cUFlwCHuU5feQ7yxfsewcAwCLcBGAsYHQ/s640/image2.png)\n",
        "\n",
        "  As we can see from the above picture, we have prepend our task name in front of the input and pass it to the model. If we want to fine tune our model to a specific task then our inputs should be modified to \"task_name: input_sentence < /s> \" and the output should be modified to \"output_sentence < /s>\". This model then can be trained on this modified input and output sequences.\n",
        "\n",
        "\n",
        "\n",
        "To explore this model:\n",
        "\n",
        "1. [T5 Paper](https://arxiv.org/abs/1910.10683)\n",
        "\n",
        "2. [A Brief Paper Analysis](https://towardsdatascience.com/t5-text-to-text-transformer-a-brief-paper-analysis-e4bba797bd68)\n",
        "\n",
        "3. [Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)\n",
        "\n",
        "4. [Collin Rafel's Talk](https://www.youtube.com/watch?v=eKqWC577WlI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u836VjQ2aPY",
        "colab_type": "text"
      },
      "source": [
        "## Bart (Encoder decoder transformer)\n",
        "\n",
        "This is similar to the T5 model. This was released by the Facebook's AI team. To explore more about this model I suggest you to go through these links:\n",
        "\n",
        "1. [Blog Post](https://mc.ai/introducing-bart-combining-the-power-of-bert-and-gpt/)\n",
        "\n",
        "2. [Introducing BART](https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html)\n",
        "\n",
        "3. [BART Paper](https://www.aclweb.org/anthology/2020.acl-main.703.pdf)\n",
        "\n",
        "4. [Hugging Face Docs](https://huggingface.co/transformers/model_doc/bart.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5h9vHxs2eKE",
        "colab_type": "text"
      },
      "source": [
        "## Transformer + seq2seq model\n",
        "\n",
        "  The output from encoder models like BERT, is fed in to a seq2seq encoder-decoder model. To explore this model in detail read through the [paper](https://www.aclweb.org/anthology/D19-5627.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn-HWPP83z6Y",
        "colab_type": "text"
      },
      "source": [
        "## Encoder-Decoder model\n",
        "\n",
        "  In this model, one BERT model is used as the encoder and the other BERT model is used as a decoder. Hugging face has a method to implement this model using the Encoder-Decoder Class where we can instantiate one model as an encoder and any other model as a decoder. As of now only the support of BERT2BERT models exist. You can head to the [docs](https://huggingface.co/transformers/model_doc/encoderdecoder.html) for futher implementation details. Do note that there is no Tensorflow implementation of this Encoder-Decoder class as of now only the Pytorch bindings exist.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V__cOHPS2t4J",
        "colab_type": "text"
      },
      "source": [
        "# **Building the T5 model for fine tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVr-D8c97jOM",
        "colab_type": "text"
      },
      "source": [
        "## **Running a Pre-trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgje3Xdy74Sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "73261260-6059-4f98-b86f-69c75c67c2d8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 33.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 39.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 29.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 16.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 14.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 15.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 15.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 13.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\r\u001b[K     |▍                               | 10kB 33.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 26.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 34.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 37.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 40.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 44.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 46.7MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 48.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 49.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102kB 49.5MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 49.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122kB 49.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 194kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808kB 49.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839kB 49.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870kB 49.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880kB 49.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2df056017e1ad66a3e20a527ea1a4c5bd09b86be4f418ff20975d02f2bb59895\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZoAvqP_7tLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e8e057fa-32fa-4553-fec8-a98d3f2573c5"
      },
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_paraphraser')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device \",device)\n",
        "model = model.to(device)\n",
        "\n",
        "sentence = \"There was something in the closet so i had to be careful\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=5 # Number of sentences to return\n",
        ")\n",
        "\n",
        "print(f\"Sentence: {sentence}\")\n",
        "\n",
        "print(\"Paraphrase: \")\n",
        "\n",
        "for i,line in enumerate(beam_outputs):\n",
        "  paraphrase = tokenizer.decode(line,skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "  print(f\"{i+1}. {paraphrase}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device  cuda\n",
            "Sentence: There was something in the closet so i had to be careful\n",
            "Paraphrase: \n",
            "1. There was something in the closet that I had to be careful of.\n",
            "2. I have a stash of stuff in my closet and it does this if to get some things out of my closet.\n",
            "3. We had something in the closet but I had to be careful with it.\n",
            "4. I had to be careful in my closet for something that was hidden for a long time. I know what we were searching for and it was hidden.\n",
            "5. I keep finding things in the closet so i have to be very careful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asAs1kgl8NPr",
        "colab_type": "text"
      },
      "source": [
        "## **Fine tuning our own model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZABUXu68hph",
        "colab_type": "text"
      },
      "source": [
        "## **Fine Tuner Class**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZiXQgIsTOUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea2b7656-cc82-4c8a-8749-49cda86f97ea"
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/64/65a5bd6b0c286217f2e53bb067c4099c0584a8eff1d229046b9a35ae3e26/pytorch_lightning-0.8.5-py3-none-any.whl (313kB)\n",
            "\r\u001b[K     |█                               | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.2.2)\n",
            "Collecting PyYAML>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.5.1+cu101)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.12.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (49.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.30.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.17.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
            "Building wheels for collected packages: PyYAML, future\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=f0b175f17d791e3b34242310e374f18052071f85dd6ff28e8bb4ffa05bc96bef\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=335ace899e44a73a349b7219baddac709539d06d47f01f1ed0f166ae91ba1530\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built PyYAML future\n",
            "Installing collected packages: PyYAML, future, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.3.1 future-0.18.2 pytorch-lightning-0.8.5\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bd0fd0db9c4c8596745f4cb09e811148a00a300453dc25f5d9e34494093cd695\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7izi0clHdsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "832db418-9aba-4f28-d6ef-c37ab85135d0"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbe6w5MaUMlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMYxygFyW_bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "\n",
        "  def __init__(self,hparams):\n",
        "\n",
        "    # Calling the super constructer\n",
        "    super(T5FineTuner,self).__init__()\n",
        "\n",
        "    self.hparams = hparams\n",
        "\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None):\n",
        "\n",
        "    return self.model(input_ids, attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            lm_labels=lm_labels,)\n",
        "    \n",
        "  def is_logger(self):\n",
        "      return self.trainer.proc_rank <= 0\n",
        "    \n",
        "\n",
        "  def _step(self, batch):\n",
        "        lm_labels = batch[\"target_ids\"]\n",
        "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            lm_labels=lm_labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      loss = self._step(batch)\n",
        "\n",
        "      tensorboard_logs = {\"train_loss\": loss}\n",
        "      return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "      avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "      tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "      return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "      loss = self._step(batch)\n",
        "      return {\"val_loss\": loss}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "      avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "      tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "      return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "\n",
        "\n",
        "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, using_native_amp=None):\n",
        "    if self.trainer.use_tpu:\n",
        "        xm.optimizer_step(optimizer)\n",
        "    else:\n",
        "        optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "\n",
        "\n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = CustomDataset(tokenizer=self.tokenizer, type_path=\"PAW_Train_Global\",data_dir=self.hparams.data_dir, max_len=self.hparams.max_seq_length)\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n",
        "                            num_workers=4)\n",
        "    t_total = (\n",
        "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "            // self.hparams.gradient_accumulation_steps\n",
        "            * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = CustomDataset(tokenizer=self.tokenizer, type_path=\"PAW_Test_Global\",data_dir=self.hparams.data_dir, max_len=self.hparams.max_seq_length)\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr9vSnvEmtRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "  def on_test_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Test results *****\")\n",
        "\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "\n",
        "      # Log and save results to file\n",
        "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "      with open(output_test_results_file, \"w\") as writer:\n",
        "        for key in sorted(metrics):\n",
        "          if key not in [\"log\", \"progress_bar\"]:\n",
        "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnov41XemyC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_seq_length=512,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=6,\n",
        "    eval_batch_size=6,\n",
        "    num_train_epochs=2,\n",
        "    gradient_accumulation_steps=16,\n",
        "    n_gpu=1,\n",
        "    early_stop_callback=False,\n",
        "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
        "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
        "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
        "    seed=42,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYQ-QwM3m5Qa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ce2a004205f747c1baa6d977883b7854",
            "858358c5ff854976953ae82885215fc9",
            "3547d1312d694841bd2de6a7040ad99d",
            "0354bc75a1dd4a7f95b455453fc8738d",
            "5550f5993b2046eda7bd4a44646194b9",
            "d769ce10acd64ba5b461b5d541b965fd",
            "85d6dcad7b9c427dbb46f2c73955d1ff",
            "59a6614a0a854a01b8b2c85001648871"
          ]
        },
        "outputId": "9b0fdf65-64cd-4120-8ee5-26499f411b37"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data_dir, type_path, max_len=256):\n",
        "        # self.path = os.path.join(data_dir, type_path + '.csv')\n",
        "\n",
        "        self.source_column = \"question1\"\n",
        "        self.target_column = \"question2\"\n",
        "        \n",
        "        self.data = []\n",
        "        \n",
        "        with open(type_path+\".csv\",\"r\") as csv_file:\n",
        "          csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "          line_count = 0\n",
        "          for row in csv_reader:\n",
        "            self.data.append(row)\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "\n",
        "    def _build(self):\n",
        "        for example in self.data:\n",
        "            \n",
        "            input_ = example[0]\n",
        "            target = example[1]\n",
        "\n",
        "            input_ = \"paraphrase: \"+ input_ + ' </s>'\n",
        "            target = target + \" </s>\"\n",
        "\n",
        "            # tokenize inputs\n",
        "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [input_], max_length=self.max_len, pad_to_max_length=True, truncation=True, return_tensors=\"pt\"\n",
        "            )\n",
        "            # tokenize targets\n",
        "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                [target], max_length=self.max_len, pad_to_max_length=True,truncation=True, return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            self.inputs.append(tokenized_inputs)\n",
        "            self.targets.append(tokenized_targets)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2a004205f747c1baa6d977883b7854",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02XVrE2bgAEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_dataset(tokenizer, type_path, args):\n",
        "#   return CustomDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dhHFRpr8bGp",
        "colab_type": "text"
      },
      "source": [
        "## Quora Question Pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oI59jB-ge-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preparation\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(ds_train,ds_test,ds_validation) ,ds_info = tfds.load(\"glue/qqp\",split=[\"train\",\"test\",\"validation\"],with_info=True)\n",
        "\n",
        "print(ds_info)\n",
        "\n",
        "\n",
        "train_examples = []\n",
        "test_examples = []\n",
        "\n",
        "\n",
        "for example in ds_train:\n",
        "\n",
        "  if(example[\"label\"] == 1):\n",
        "    train_examples.append((example[\"question1\"].numpy().decode(),example[\"question2\"].numpy().decode()))\n",
        "  \n",
        "\n",
        "for example in ds_validation:\n",
        "  \n",
        "  if(example[\"label\"] == 1):\n",
        "    test_examples.append((example[\"question1\"].numpy().decode(),example[\"question2\"].numpy().decode()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQDrdyY81Xkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('Train.csv','w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    # csv_out.writerow(['question1',''])\n",
        "    for row in train_examples:\n",
        "        csv_out.writerow(row)\n",
        "\n",
        "with open('Test.csv','w') as out:\n",
        "    csv_out = csv.writer(out)\n",
        "\n",
        "    for row in test_examples:\n",
        "        csv_out.writerow(row)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvlwvO-RgYNC",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('t5_QQP'):\n",
        "    os.makedirs('t5_QQP')\n",
        "\n",
        "\n",
        "args_dict.update({'output_dir': 't5_paraphrase','num_train_epochs':3,'max_seq_length':256})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PR8-OpePgYNI",
        "colab": {}
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YItBVqorgYNM",
        "colab": {}
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5wobR4p_gYNQ",
        "colab": {}
      },
      "source": [
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "print (\" Training model\")\n",
        "trainer.fit(model)\n",
        "\n",
        "print (\"training finished\")\n",
        "\n",
        "print (\"Saving model\")\n",
        "model.model.save_pretrained('t5_paraphrase')\n",
        "\n",
        "print (\"Saved model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1D_hqHR_P56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "d6367fe6-7428-4456-fdb5-9e43fefc223c"
      },
      "source": [
        "# Getting the output\n",
        "\n",
        "\n",
        "# model = T5ForConditionalGeneration.from_pretrained('./t5_paraphraser')\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "sentence = \"In order to make something we have to work hard.\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "# Have to read about these decodings\n",
        "beam_outputs = model.model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=10\n",
        ")\n",
        "\n",
        "\n",
        "print (\"\\nOriginal Question ::\")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased Questions :: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original Question ::\n",
            "In order to make something we have to work hard.\n",
            "\n",
            "\n",
            "Paraphrased Questions :: \n",
            "0: To Make Something you can also work hard.\n",
            "1: How to write will work hard if there’s not enough.\n",
            "2: The most basic equation is free speech technology but it can be used to create someone wrong.\n",
            "3: Now we have to work hard...\n",
            "4: Make her guess is sure to work for a lot of others.\n",
            "5: How important is making something necessary.\n",
            "6: But when thinking about it, we should have a hard learning experience.\n",
            "7: As a society you can expect to make something into your work.\n",
            "8: Whether we create something is an investment do enough to push this way.\n",
            "9: To learn a little we are trying to make something a dream.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBENy2R68nNh",
        "colab_type": "text"
      },
      "source": [
        "## MRPC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I6HexVzgaHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Preparation\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(ds_train,ds_test,ds_validation),ds_info = tfds.load(\"glue/mrpc\",split=[\"train\",\"test\",\"validation\"],with_info=True)\n",
        "\n",
        "\n",
        "mrpc_train = []\n",
        "mrpc_test = []\n",
        "\n",
        "\n",
        "for example in ds_train:\n",
        "\n",
        "  if(example[\"label\"] == 1):\n",
        "    mrpc_train.append((example[\"sentence1\"].numpy().decode(),example[\"sentence2\"].numpy().decode()))\n",
        "  \n",
        "\n",
        "for example in ds_validation:\n",
        "  \n",
        "  if(example[\"label\"] == 1):\n",
        "    mrpc_test.append((example[\"sentence1\"].numpy().decode(),example[\"sentence2\"].numpy().decode()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnURMeug2Hnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('MRPC_Train.csv','w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    # csv_out.writerow(['question1',''])\n",
        "    for row in mrpc_train:\n",
        "        csv_out.writerow(row)\n",
        "\n",
        "with open('MRPC_Test.csv','w') as out:\n",
        "    csv_out = csv.writer(out)\n",
        "\n",
        "    for row in mrpc_test:\n",
        "        csv_out.writerow(row)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "seZjZpBVgaXL",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('t5_mrpc'):\n",
        "    os.makedirs('t5_mrpc')\n",
        "\n",
        "\n",
        "args_dict.update({'output_dir': 't5_mrpc','num_train_epochs':5,'max_seq_length':256})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewDnefM_gaXS",
        "colab": {}
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sSieOxhOgaXW",
        "colab": {}
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxH5ADRqgaXa",
        "colab": {}
      },
      "source": [
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "print (\" Training model\")\n",
        "5: How important is making something necessary.\n",
        "trainer.fit(model)\n",
        "\n",
        "print (\"training finished\")\n",
        "\n",
        "print (\"Saving model\")\n",
        "model.model.save_pretrained('t5_paraphrase')\n",
        "\n",
        "print (\"Saved model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJzLXzJFe1xN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "4e41f2f3-75d2-4e2e-d684-b72820eeede6"
      },
      "source": [
        "sentence = \"In order to make something we have to work hard.\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "# Have to read about these decodings\n",
        "beam_outputs = model.model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=10\n",
        ")\n",
        "\n",
        "\n",
        "print (\"\\nOriginal Question ::\")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased Questions :: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original Question ::\n",
            "In order to make something we have to work hard.\n",
            "\n",
            "\n",
            "Paraphrased Questions :: \n",
            "0: In order to make something the people wants us to work harder.\n",
            "1: As many people we get rid of, people work hard to create the product people!\n",
            "2: The purpose of the law is to work hard to make something one more.\n",
            "3: Just enter the story in yourself, in order to make something, some people should work hard.\n",
            "4: Rather, in order to do a man something is to work hard.\n",
            "5: Pour une réalisation, we know that we are not capable of being more self-heavy.\n",
            "6: Eroldened a career from life without technology.\n",
            "7: Our main advantages are the ability to work hard.\n",
            "8: To do things and work we have to work hard.\n",
            "9: Just because of our work, we have to work hard.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bxMTDtY8q1D",
        "colab_type": "text"
      },
      "source": [
        "## MS COCO Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mzkp6cIgbLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "ba08bb7e-9188-4229-85b0-b2e63a7761f7"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "## Downloading the coco dataset and unzipping the content\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 11:03:20--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.77.204\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.77.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  80.9MB/s    in 3.0s    \n",
            "\n",
            "2020-07-15 11:03:23 (80.9 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IwwmYOh2cfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "paraphrase_examples = []\n",
        "paraphrase_test = []\n",
        "\n",
        "with open(\"annotations/captions_train2017.json\",\"r\") as file:\n",
        "\n",
        "  data = json.load(file)\n",
        "\n",
        "\n",
        "  annotations = data[\"annotations\"]\n",
        "\n",
        "  annotations.sort(key=lambda x:x[\"image_id\"])\n",
        "\n",
        "\n",
        "with open(\"annotations/captions_val2017.json\",\"r\") as file:\n",
        "\n",
        "  data_test = json.load(file)\n",
        "\n",
        "  annotations_test = data_test[\"annotations\"]\n",
        "\n",
        "  annotations_test.sort(key=lambda x:x[\"image_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OBSgNbG2iy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for examples in range(0,len(annotations),5):\n",
        "\n",
        "    pairs = annotations[examples:examples+5]\n",
        "\n",
        "\n",
        "    if(len(pairs) >= 4):\n",
        "\n",
        "      paraphrase_examples.append((pairs[0]['caption'],pairs[1]['caption']))\n",
        "\n",
        "      paraphrase_examples.append((pairs[2]['caption'],pairs[3]['caption']))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for examples in range(0,len(annotations_test),5):\n",
        "\n",
        "    pairs = annotations_test[examples:examples+5]\n",
        "\n",
        "\n",
        "    if(len(pairs) >= 4):\n",
        "\n",
        "      paraphrase_test.append((pairs[0]['caption'],pairs[1]['caption']))\n",
        "\n",
        "      paraphrase_test.append((pairs[2]['caption'],pairs[3]['caption']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PNZpeKv2q2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2e05daae-2c9f-42af-f5a8-3f6f1882575b"
      },
      "source": [
        "print(len(paraphrase_examples),len(paraphrase_test))\n",
        "ind = len(paraphrase_examples)//2\n",
        "paraphrase_examples = paraphrase_examples[:ind]\n",
        "print(len(paraphrase_examples))\n",
        "print(paraphrase_examples[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "236700 10006\n",
            "118350\n",
            "('Closeup of bins of food that include broccoli and bread.', 'A meal is presented in brightly colored plastic trays.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVn3QRos2row",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(\"COCO_Train.csv\",\"w\") as file:\n",
        "\n",
        "  csv_out = csv.writer(file)\n",
        "\n",
        "  for row in paraphrase_examples:\n",
        "\n",
        "    csv_out.writerow(row)\n",
        "\n",
        "\n",
        "with open(\"COCO_Test.csv\",\"w\") as file:\n",
        "\n",
        "  csv_out = csv.writer(file)\n",
        "\n",
        "  for row in paraphrase_test:\n",
        "\n",
        "    csv_out.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z3G6u8VLgcJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a76eb09d-afd8-4d29-cb32-5f8a1ebecccd"
      },
      "source": [
        "if not os.path.exists('t5_coco'):\n",
        "    os.makedirs('t5_coco')\n",
        "\n",
        "args_dict.update({'output_dir': 't5_coco','num_train_epochs':1,'max_seq_length':256})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data_dir': '', 'output_dir': 't5_coco', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'max_seq_length': 256, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 6, 'eval_batch_size': 6, 'num_train_epochs': 1, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wAJ8C6YfgcJE",
        "colab": {}
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AnMOEqfgcJG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "5154b87298ce4077bca8dde67e58de13",
            "1d3a9a01d6b64fdd9d8deafbeecf09ae",
            "b75fccffbfd247bd82c9afff18d6964d",
            "2a9a11a07b834b6e99f2971651bb8250",
            "fc01faeb2e334433827fb0ecdbbc2b81",
            "da28babc5c7446bdbab89e5d3ec6049b",
            "6d6cbc0886d540ce83868319458c046e",
            "1126c244e0d24e939e92e055740f04f9",
            "99c13a5d0ae14ebc9368e5c0997da1e9",
            "8461ae940e3349bea83021aec3ac90bc",
            "582f4b1e62de4ac18d8913fa64411682",
            "424bc4bc00c04353827ef6532f38e376",
            "eee45c1d726741d291e9d8cf5c442df6",
            "a668a78ce8bb437db40b872e9e305e82",
            "4b20a09bd3444e449f9a97c8d04da889",
            "50fd06b167474d529a610cb25be68974"
          ]
        },
        "outputId": "495a6c5a-da34-487f-f4fe-a72bfc11a960"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5154b87298ce4077bca8dde67e58de13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1197.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c13a5d0ae14ebc9368e5c0997da1e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=242136741.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-small were not used when initializing T5ForConditionalGeneration: ['encoder.block.0.layer.0.layer_norm.bias', 'encoder.block.0.layer.1.layer_norm.bias', 'encoder.block.1.layer.0.layer_norm.bias', 'encoder.block.1.layer.1.layer_norm.bias', 'encoder.block.2.layer.0.layer_norm.bias', 'encoder.block.2.layer.1.layer_norm.bias', 'encoder.block.3.layer.0.layer_norm.bias', 'encoder.block.3.layer.1.layer_norm.bias', 'encoder.block.4.layer.0.layer_norm.bias', 'encoder.block.4.layer.1.layer_norm.bias', 'encoder.block.5.layer.0.layer_norm.bias', 'encoder.block.5.layer.1.layer_norm.bias', 'encoder.final_layer_norm.bias', 'decoder.block.0.layer.0.layer_norm.bias', 'decoder.block.0.layer.1.layer_norm.bias', 'decoder.block.0.layer.2.layer_norm.bias', 'decoder.block.1.layer.0.layer_norm.bias', 'decoder.block.1.layer.1.layer_norm.bias', 'decoder.block.1.layer.2.layer_norm.bias', 'decoder.block.2.layer.0.layer_norm.bias', 'decoder.block.2.layer.1.layer_norm.bias', 'decoder.block.2.layer.2.layer_norm.bias', 'decoder.block.3.layer.0.layer_norm.bias', 'decoder.block.3.layer.1.layer_norm.bias', 'decoder.block.3.layer.2.layer_norm.bias', 'decoder.block.4.layer.0.layer_norm.bias', 'decoder.block.4.layer.1.layer_norm.bias', 'decoder.block.4.layer.2.layer_norm.bias', 'decoder.block.5.layer.0.layer_norm.bias', 'decoder.block.5.layer.1.layer_norm.bias', 'decoder.block.5.layer.2.layer_norm.bias', 'decoder.final_layer_norm.bias']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKtOXhWegcJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "feff9a619c3a41d7b2d70af0a9b7d88f",
            "120f5850f5884406986ab27d52072dc9",
            "926d241d3c9d4580ad46b3e196566008",
            "98957ff00f894359aea0000a006c463f",
            "ac91897e332e477bac4358fe62bf4c14",
            "eb1fce035c5242ab91a80d6577972951",
            "e0f6af553b464390be3aeba125d1bf30",
            "dd566ff884e748a8a809fd1acc9c6fd8",
            "881e88c71fc746c08c4b83b995835e37",
            "728c5193752b4923817e6f3308c30408",
            "79ab9454c46046f897a1b548ede87e89",
            "ec32bd8bd31a4f68898477d1be39c338",
            "413a3bc19fbb45a09b16aee63315008e",
            "992565b9af974b3fbd273a3816eb9e18",
            "0fa3a0e366fa4474a758b99e1c9e3ca9",
            "bd6fab875ce24430b55d97948c70395e",
            "57603540902c44bb9b4f5eb540e6e7f3",
            "da887a8692fb49b3af53ccf3545ad9b2",
            "6ec5c313ccc04f8eb20d7de548c38d81",
            "03171cdbff0c40e2a9598466930bbe68",
            "b6935f3a3e0f43688e24ad9ecb0f8744",
            "f32bd274651f461495219423240cc89b",
            "917b468d2b1c4bbab80a49ebe7d47224",
            "f2553c3e2b2b4214a75e7c0092de897d"
          ]
        },
        "outputId": "329f862b-d7fe-4bc8-bae4-485c5a8f546d"
      },
      "source": [
        "\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "print (\" Training model\")\n",
        "trainer.fit(model)\n",
        "\n",
        "print (\"training finished\")\n",
        "\n",
        "print (\"Saving model\")\n",
        "model.model.save_pretrained('t5_paraphrase')\n",
        "\n",
        "print (\"Saved model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Training model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 60 M  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feff9a619c3a41d7b2d70af0a9b7d88f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "881e88c71fc746c08c4b83b995835e37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57603540902c44bb9b4f5eb540e6e7f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training finished\n",
            "Saving model\n",
            "Saved model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNLJ3gKiUMUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f869c037-9a15-441f-a6e6-f240bd82c50f"
      },
      "source": [
        "# Getting the output\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5_paraphrase')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "sentence = \"People are so fragile that i cannot even perceive this intuition\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "# Have to read about these decodings\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=120,\n",
        "    top_p=0.98,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=5\n",
        ")\n",
        "\n",
        "\n",
        "print (\"\\nOriginal Question ::\")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased Questions :: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original Question ::\n",
            "People are so fragile that i cannot even perceive this intuition\n",
            "\n",
            "\n",
            "Paraphrased Questions :: \n",
            "0: A hand tilts and twists on a glass balcony.\n",
            "1: Some people in the woods and some people in the woods.\n",
            "2: A man doing a trick on his hand.\n",
            "3: A blind dog on a bridge in a grass field.\n",
            "4: A group of people that are going through a physical relationship.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfeG45pEpBPz",
        "colab_type": "text"
      },
      "source": [
        "# Google's PAW Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HYVOA6K_Ld3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "cf8257e6-0642-4549-b2fa-89e000483107"
      },
      "source": [
        "!wget https://storage.googleapis.com/paws/english/paws_wiki_labeled_final.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-18 07:31:23--  https://storage.googleapis.com/paws/english/paws_wiki_labeled_final.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 108.177.125.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4687157 (4.5M) [application/gzip]\n",
            "Saving to: ‘paws_wiki_labeled_final.tar.gz’\n",
            "\n",
            "paws_wiki_labeled_f 100%[===================>]   4.47M  3.66MB/s    in 1.2s    \n",
            "\n",
            "2020-07-18 07:31:25 (3.66 MB/s) - ‘paws_wiki_labeled_final.tar.gz’ saved [4687157/4687157]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbVHDV2xtg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar -xzf paws_wiki_labeled_final.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o1SL4CXx0xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "train_examples = []\n",
        "test_examples = []\n",
        "dev_examples = []\n",
        "\n",
        "with open(\"final/train.tsv\",\"r\") as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile,delimiter=\"\\t\")\n",
        "  \n",
        "  next(reader)\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "    if row[3] == \"1\":\n",
        "      train_examples.append((row[1],row[2]))\n",
        "\n",
        "\n",
        "\n",
        "with open(\"final/test.tsv\",\"r\") as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile,delimiter=\"\\t\")\n",
        "  \n",
        "  next(reader)\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "    if row[3] == \"1\":\n",
        "      test_examples.append((row[1],row[2]))\n",
        "\n",
        "\n",
        "with open(\"final/dev.tsv\",\"r\") as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile,delimiter=\"\\t\")\n",
        "  \n",
        "  next(reader)\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "    if row[3] == \"1\":\n",
        "      dev_examples.append((row[1],row[2]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp1HS8JR1A3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_examples = dev_examples + test_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXmyYNo2e9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "139231b2-b49d-47cd-bf8c-aa46142e6d5e"
      },
      "source": [
        "len(test_examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAYxTZgk4CGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"PAW_Train.csv\",\"w\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "\n",
        "  for row in train_examples:\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-rnd7rI4WuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"PAW_Test.csv\",\"w\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "\n",
        "  for row in test_examples:\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S387fCU240hu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "224d790e-3a4b-431f-fe19-be407f9fb292"
      },
      "source": [
        "if not os.path.exists('t5_paw_global'):\n",
        "    os.makedirs('t5_paw_global')\n",
        "\n",
        "args_dict.update({'output_dir': 't5_paw_global','num_train_epochs':1,'max_seq_length':256})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data_dir': '', 'output_dir': 't5_paw_global', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_seq_length': 256, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 6, 'eval_batch_size': 6, 'num_train_epochs': 1, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NzIJnndg40hz",
        "colab": {}
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=False,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLfmRbNs5DNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "564cade8cd174b029cd3fb0309f11ea0",
            "d059ada38ccf422587bb5a2965770fb5",
            "c8877bd13efc4a249a394fba17ac757e",
            "72ec234f136941edbbedf1ab97596a37",
            "1553dc027e51406e9ea132e25b1e4ddf",
            "b84293a0ae72438c8c92061698397698",
            "0fcc6ea53c354b62b979ecf4d6c1245c",
            "111991ccfc4b48e3b023de8ed9f09d48",
            "fb267d475796426fb446b34563a7f452",
            "1aa0462c01ba4c31944d1ed41670ed2a",
            "db644836130d4af38dc37a876cae00d4",
            "bc3fb47151ff48188e9dcf24b5650460",
            "3abffa9077cf43ccaae7e907d2a06ba3",
            "bc9d1ad29fe24958a9bf966562fd3a8c",
            "8ed59c36715845aa9f6e60614c1b1e13",
            "cff1f564dfb74ebd9a63b3dac35573b8"
          ]
        },
        "outputId": "3261f372-8f30-4d26-cc2a-2044f01d8909"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "564cade8cd174b029cd3fb0309f11ea0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb267d475796426fb446b34563a7f452",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PTHai9ot40h2",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "trainer = pl.Trainer(**train_params)\n",
        "\n",
        "print (\" Training model\")\n",
        "trainer.fit(model)\n",
        "\n",
        "print (\"training finished\")\n",
        "\n",
        "print (\"Saving model\")\n",
        "model.model.save_pretrained('t5_paw_global')\n",
        "\n",
        "print (\"Saved model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi5HhVBt5Afv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b320adc2-f601-4a93-d982-f51ced7bd4df"
      },
      "source": [
        "# Getting the output\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5_paraphrase')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "sentence = \"This is something which i cannot understand at all\"\n",
        "\n",
        "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "# Have to read about these decodings\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    do_sample=True,\n",
        "    max_length=256,\n",
        "    top_k=220,\n",
        "    top_p=1,\n",
        "    early_stopping=True,\n",
        "    num_return_sequences=5\n",
        ")\n",
        "\n",
        "\n",
        "print (\"\\nOriginal Question ::\")\n",
        "print (sentence)\n",
        "print (\"\\n\")\n",
        "print (\"Paraphrased Questions :: \")\n",
        "final_outputs =[]\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "        final_outputs.append(sent)\n",
        "\n",
        "for i, final_output in enumerate(final_outputs):\n",
        "    print(\"{}: {}\".format(i, final_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original Question ::\n",
            "This is something which i cannot understand at all\n",
            "\n",
            "\n",
            "Paraphrased Questions :: \n",
            "0: This is something I cannot understand at all so there is nothing i could understand it at all.\n",
            "1: This is something that i can have absolutely no comprehension of.\n",
            "2: This is something which i cannot explain at all.\n",
            "3: ... It is something at all that i can not understand myself at.\n",
            "4: This is something i cannot understand at all.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdOXfnJs-pk3",
        "colab_type": "text"
      },
      "source": [
        "### Additonal Training Data From PAWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwUc74EVCEI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "0806526f-b5c7-41b1-92d4-3dda93fbca60"
      },
      "source": [
        "!wget https://storage.googleapis.com/paws/english/paws_wiki_unlabeled_final.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-18 03:39:59--  https://storage.googleapis.com/paws/english/paws_wiki_unlabeled_final.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.119.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47393331 (45M) [application/gzip]\n",
            "Saving to: ‘paws_wiki_unlabeled_final.tar.gz’\n",
            "\n",
            "paws_wiki_unlabeled 100%[===================>]  45.20M  45.3MB/s    in 1.0s    \n",
            "\n",
            "2020-07-18 03:40:01 (45.3 MB/s) - ‘paws_wiki_unlabeled_final.tar.gz’ saved [47393331/47393331]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS_x6uCSmRBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!tar -xzf paws_wiki_unlabeled_final.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Kp-iXQmZOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabeled_train = []\n",
        "unlabeled_test = []\n",
        "\n",
        "\n",
        "with open(\"unlabeled/final/train.tsv\",\"r\") as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile,delimiter=\"\\t\")\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "    if row[3] == \"1\":\n",
        "      unlabeled_train.append((row[1],row[2]))\n",
        "\n",
        "with open(\"unlabeled/final/dev.tsv\",\"r\") as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile,delimiter=\"\\t\")\n",
        "\n",
        "  for row in reader:\n",
        "\n",
        "    if row[3] == \"1\":\n",
        "      unlabeled_test.append((row[1],row[2]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDTdumSiAe6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "943b2652-5312-4171-ce31-8ca0ec4f9a9f"
      },
      "source": [
        "ind = len(unlabeled_train) // 3\n",
        "print(ind)\n",
        "unlabeled_train = unlabeled_train[:ind]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_TaYuknAkFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52ecac84-3aca-4cb9-b62e-ee73fb70411d"
      },
      "source": [
        "len(unlabeled_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqCqV-xpnLxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_examples + unlabeled_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFPZuDk-oiZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = test_examples + unlabeled_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ahsW-5nBJzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nXTAsbWHX78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4500362-d75b-4fad-a1b8-c76aeb50f788"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66l0oS3nWSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"PAW_Train_Global.csv\",\"w\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "\n",
        "  for row in train_data:\n",
        "    writer.writerow(row)\n",
        "\n",
        "\n",
        "with open(\"PAW_Test_Global.csv\",\"w\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "\n",
        "  for row in test_data:\n",
        "    writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}